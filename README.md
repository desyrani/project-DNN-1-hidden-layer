**Overview**

This repository focuses on the implementation and analysis of a simple Deep Neural Network (DNN) with a single hidden layer. The project demonstrates the fundamental principles of neural networks, including forward propagation, backpropagation, and optimization, while balancing simplicity and functionality.

By exploring this architecture, the project investigates how a single hidden layer performs in solving tasks such as classification, regression, and binary decision-making.

**Key Features**

**1 Hidden Layer Architecture:**

- Customizable number of neurons in the hidden layer.
- Configurable activation functions: Sigmoid, ReLU, Tanh, etc.

**Training and Evaluation:**

- Training on datasets like MNIST, XOR, and synthetic datasets.
- Performance analysis based on accuracy, loss, and learning curves.

**Ease of Use:**

- Beginner-friendly code for understanding the basics of DNNs.
- Clear visualization of results, including decision boundaries and predictions.
